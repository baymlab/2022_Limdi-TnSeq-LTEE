{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, I'm finding all the TA sites represented in the t-1 data and finding the corresponding counts at that site for the other time points. I'll save the merged data as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input directory with all the counts data\n",
    "directory = #'/Volumes/GoogleDrive/My Drive/novaseq_data/counts_r2_UMI/ara_minus'\n",
    "##YOUR INPUT DIRECTORY HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output directory for combined data\n",
    "outpath = #'/Volumes/GoogleDrive/My Drive/novaseq_data/merged_trajectory_r2_UMI'\n",
    "##YOUR OUTPUT DIRECTORY HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search query for sample name\n",
    "search = r'_S(.*)_merged'\n",
    "#create a dictionary: sample names are keys, path to textfiles with counts data are values\n",
    "dict_files = {}\n",
    "for filename in os.listdir(directory):\n",
    "    sample = int(re.search(search,filename).group(1))\n",
    "    filepath = os.path.join(directory,filename)\n",
    "    dict_files[sample] = filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraries = ['REL606', 'REL607', 'REL11330', 'REL11333', 'REL11364', 'REL11336', 'REL11339', 'REL11389', 'REL11392', 'REL11342', 'REL11345', 'REL11348', 'REL11367', 'REL11370', 'methods_old', 'methods_new']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now I'm going to count how many reads are present at every TA site (note that there are 211995 ta sites in the REl606 reference genome). This should make it much easier to combine all the data into one single array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/anuraglimdi/Desktop/TnSeq_LTEE/ReferenceGenome/rel606_reference.fasta\") as in_handle:\n",
    "    for title, seq in SimpleFastaParser(in_handle):\n",
    "        ta_sites = [m.start(0) for m in re.finditer('TA', seq)]\n",
    "ta_sites = np.array(ta_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_ta_sites(keys,population):\n",
    "    #ensure that there are enough keys\n",
    "    assert len(keys)==9, \"Input keys array should be of length 9\"\n",
    "    #loading the data\n",
    "    tm1 = np.loadtxt(dict_files[keys[0]])\n",
    "    t0_red = np.loadtxt(dict_files[keys[1]])\n",
    "    t0_green = np.loadtxt(dict_files[keys[2]])\n",
    "    t1_red = np.loadtxt(dict_files[keys[3]])\n",
    "    t1_green = np.loadtxt(dict_files[keys[4]])\n",
    "    t2_red = np.loadtxt(dict_files[keys[5]])\n",
    "    t2_green = np.loadtxt(dict_files[keys[6]])\n",
    "    t3_red = np.loadtxt(dict_files[keys[7]])\n",
    "    t3_green = np.loadtxt(dict_files[keys[8]])\n",
    "    #making empty arrays for storing counts\n",
    "    #each row corresponds to a timepoint\n",
    "    counts_site_green = np.zeros([11,len(ta_sites)])\n",
    "    counts_site_red = np.zeros([11,len(ta_sites)])\n",
    "    #the first row is simply the list of TA sites\n",
    "    counts_site_green[0,:] = ta_sites\n",
    "    counts_site_red[0,:] = ta_sites\n",
    "    #one row for the list of ta_sites\n",
    "    #10 rows, one for each time point, with UMI uncorrected and corrected counts\n",
    "     #first the green replicate\n",
    "    t0 = time.time()\n",
    "    for i in range(0, len(ta_sites)):\n",
    "        query = ta_sites[i]\n",
    "        #if the site is present in t0_green data\n",
    "        if query in tm1[0,:]:\n",
    "            counts_site_green[1,i] = tm1[1,np.where(tm1[0,:]==query)]\n",
    "            counts_site_green[2,i] = tm1[2,np.where(tm1[0,:]==query)]\n",
    "       #if the site is present in t0_green data\n",
    "        if query in t0_green[0,:]:\n",
    "            #extract the corresponding counts\n",
    "            counts_site_green[3,i] = t0_green[1,np.where(t0_green[0,:]==query)]\n",
    "            counts_site_green[4,i] = t0_green[2,np.where(t0_green[0,:]==query)]\n",
    "        if query in t1_green[0,:]:\n",
    "            counts_site_green[5,i] = t1_green[1,np.where(t1_green[0,:]==query)]\n",
    "            counts_site_green[6,i] = t1_green[2,np.where(t1_green[0,:]==query)]\n",
    "        if query in t2_green[0,:]:\n",
    "            counts_site_green[7,i] = t2_green[1,np.where(t2_green[0,:]==query)]\n",
    "            counts_site_green[8,i] = t2_green[2,np.where(t2_green[0,:]==query)]\n",
    "        if query in t3_green[0,:]:\n",
    "            counts_site_green[9,i] = t3_green[1,np.where(t3_green[0,:]==query)]\n",
    "            counts_site_green[10,i] = t3_green[2,np.where(t3_green[0,:]==query)]\n",
    "    t1 = time.time()\n",
    "    print(t1-t0)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    for i in range(0, len(ta_sites)):\n",
    "        query = ta_sites[i]\n",
    "        #if the site is present in t0_red data\n",
    "        if query in tm1[0,:]:\n",
    "            counts_site_red[1,i] = tm1[1,np.where(tm1[0,:]==query)]\n",
    "            counts_site_red[2,i] = tm1[2,np.where(tm1[0,:]==query)]\n",
    "       #if the site is present in t0_red data\n",
    "        if query in t0_red[0,:]:\n",
    "            #extract the corresponding counts\n",
    "            counts_site_red[3,i] = t0_red[1,np.where(t0_red[0,:]==query)]\n",
    "            counts_site_red[4,i] = t0_red[2,np.where(t0_red[0,:]==query)]\n",
    "        if query in t1_red[0,:]:\n",
    "            counts_site_red[5,i] = t1_red[1,np.where(t1_red[0,:]==query)]\n",
    "            counts_site_red[6,i] = t1_red[2,np.where(t1_red[0,:]==query)]\n",
    "        if query in t2_red[0,:]:\n",
    "            counts_site_red[7,i] = t2_red[1,np.where(t2_red[0,:]==query)]\n",
    "            counts_site_red[8,i] = t2_red[2,np.where(t2_red[0,:]==query)]\n",
    "        if query in t3_red[0,:]:\n",
    "            counts_site_red[9,i] = t3_red[1,np.where(t3_red[0,:]==query)]\n",
    "            counts_site_red[10,i] = t3_red[2,np.where(t3_red[0,:]==query)]\n",
    "    t1 = time.time()\n",
    "    print(t1-t0)\n",
    "\n",
    "    gname = outpath+'/green_'+population+'_merged_all_TAsites.txt'\n",
    "    rname = outpath+'/red_'+population+'_merged_all_TAsites.txt'\n",
    "\n",
    "\n",
    "    \n",
    "    np.savetxt(gname, counts_site_green, comments=f'#{population}, col 0: TA sites, col 1,2: t-1 counts, uncorrected and UMI corrected resp., col 3,4: t0green counts,uncorrected and UMI corrected resp. col 5,6: t1green counts, uncorrected and UMI corrected resp. col 7,8: t2green counts, uncorrected and UMI corrected resp., col 9,10: t3green counts, uncorrected and UMI corrected resp.')\n",
    "    np.savetxt(rname, counts_site_red, comments=f'#{population}, col 0: TA sites, col 1,2: t-1 counts, uncorrected and UMI corrected resp., col 3,4: t0red counts,uncorrected and UMI corrected resp. col 5,6: t1red counts, uncorrected and UMI corrected resp. col 7,8: t2red counts, uncorrected and UMI corrected resp., col 9,10: t3red counts, uncorrected and UMI corrected resp.')\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arranging the keys in an array\n",
    "keys = np.linspace(1,144,144)\n",
    "keys = np.reshape(keys, (9,16))\n",
    "#each column in the reshaped array corresponds to a library\n",
    "#each row corresponds to a time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc_methods = [0,1,14,15]\n",
    "ara_plus = [8,9,10,11,12,13]\n",
    "ara_minus = [2,3,4,5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REL11330\n",
      "190.98461484909058\n",
      "169.85977816581726\n",
      "REL11333\n",
      "140.4428768157959\n",
      "139.73922204971313\n",
      "REL11364\n",
      "163.18904089927673\n",
      "159.96757793426514\n",
      "REL11336\n",
      "163.61236214637756\n",
      "163.11022305488586\n",
      "REL11339\n",
      "183.90242195129395\n",
      "174.74777221679688\n",
      "REL11389\n",
      "161.64354991912842\n",
      "148.84663200378418\n"
     ]
    }
   ],
   "source": [
    "for i in ara_minus:\n",
    "    print(libraries[i])\n",
    "    merge_all_ta_sites(keys[:,i], libraries[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ara_plus:\n",
    "    print(libraries[i])\n",
    "    merge_all_ta_sites(keys[:,i], libraries[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in anc_methods:\n",
    "    print(libraries[i])\n",
    "    merge_all_ta_sites(keys[:,i], libraries[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
